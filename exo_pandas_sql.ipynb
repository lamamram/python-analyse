{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LECTURE & ECRITURE PANDAS <=> SQL\n",
    "\n",
    "* énoncé:\n",
    "  1. télécharger l'url et écrire en local si **ce n'est pas déjà fait**\n",
    "     > ATTENTION encodage **iso-8859-1**, et séparateur \";\"\n",
    "  2. se donner un dataframe avec le \"Nom de domaine\" et le \"Pays BE\" et un millions de lignes\n",
    "  3. renommer les colonnes du df comme les colonnes de la table domain_name\n",
    "  4. créer la base de données dns.db depuis le fichier .sql\n",
    "  5. connecter sqlaclhemy sur la bdd\n",
    "  6. utiliser Dataframe.to_sql pour écrire dans la table domain_name\n",
    "  7. lire table dans un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "# pip install SQLAlchemy\n",
    "# créer une connexion de bdd\n",
    "from sqlalchemy import create_engine, Column\n",
    "# pour créer / modifier un schéma de db\n",
    "from sqlalchemy.types import Integer, String, Text, CHAR\n",
    "from sqlalchemy.dialects.sqlite import insert\n",
    "URL = \"http://www.afnic.fr/wp-media/ftp/documentsOpenData/202105_OPENDATA_A-NomsDeDomaineEnPointFr.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## téléchargement et écriture en local\n",
    "encoding = \"iso-8859-1\"\n",
    "if not os.path.exists(\"dns.zip\"):\n",
    "    pd.read_csv(URL, sep=\";\", encoding=encoding).to_csv(\n",
    "        \"dns.zip\",\n",
    "        encoding=encoding,\n",
    "        compression={\n",
    "            \"method\": \"zip\",\n",
    "            \"archive_name\": \"dns.csv\"\n",
    "        },\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# élaguage\n",
    "dns_df = pd.read_csv(\n",
    "    \"dns.zip\", \n",
    "    encoding=encoding,\n",
    "    usecols=[\"Nom de domaine\", \"Pays BE\"],\n",
    "    # 1M lignes après 1M en offset \n",
    "    nrows=1000000,\n",
    "    # offset : int => depuis le \"header\" PB avec le usercols, range plsu malin\n",
    "    skiprows=range(1, 1000000)\n",
    ")\n",
    "dns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with sqlite3.connect(\"dns.db\") as conn:\n",
    "        cur = conn.cursor()\n",
    "        with open(\"domain_name_sqlite3.sql\", \"r\", encoding=\"utf8\") as f:\n",
    "            cur.executescript(f.read())\n",
    "except (\n",
    "    sqlite3.OperationalError, \n",
    "    sqlite3.DatabaseError,\n",
    "    ConnectionError\n",
    ") as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connexion sqlAlchemy\n",
    "pandas_conn = create_engine(\"sqlite:///dns.db\")\n",
    "pd.read_sql(\"pays\", pandas_conn, index_col=\"iso2\")\n",
    "pd.read_sql(\"SELECT * FROM pays\", pandas_conn, index_col=\"iso2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dns_df.rename(columns={\n",
    "    \"Nom de domaine\": \"name\",\n",
    "    \"Pays BE\": \"iso2\"\n",
    "}, inplace=True)\n",
    "dns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PAS avec SQLITE => implémenter l'update\n",
    "# def insert_on_conflict_update(table, conn, keys, data_iter):\n",
    "#     # update columns \"b\" and \"c\" on primary key conflict\n",
    "#     data = [dict(zip(keys, row)) for row in data_iter]\n",
    "#     stmt = (\n",
    "#         insert(table.table)\n",
    "#         .values(data)\n",
    "#     )\n",
    "#     print(type(stmt))\n",
    "#     stmt = stmt.on_duplicate_key_update(b=stmt.inserted[\"dns_id\"], c=stmt.inserted[\"dns_id\"])\n",
    "#     result = conn.execute(stmt)\n",
    "#     return result.rowcount\n",
    "\n",
    "print(dns_df.to_sql(\n",
    "    \"domain_name\",\n",
    "    pandas_conn,\n",
    "    # if_exists=\"replace\",\n",
    "    ## essayer de créer\n",
    "    # if_exists=\"fail\",\n",
    "\n",
    "    ## append (ajouter les lignes à la table existante)\n",
    "    if_exists=\"append\"\n",
    "    ##  utilisation de l'index comme colonne\n",
    "    index=True,\n",
    "    index_label=\"dns_id\",\n",
    "    \n",
    "    ## batch d'inserts\n",
    "    chunksize=1000,\n",
    "    ## surcharger le comportement du Insert => Insert or Update (pas avec SQLITE3)\n",
    "    # method=insert_on_conflict_update\n",
    "    \n",
    "    ## en mode replace on écrase les données autant que le SCHEMA\n",
    "    # or, les types SQLAlchemy ne peuvent pas spécifier les clés etc...\n",
    "    #  donc surcharger pd.io.sql.PandasTable ATTENTION !!!\n",
    "    ## uniquement en replace\n",
    "    # dtype={\n",
    "    #     \"dns_id\": Integer,\n",
    "    #     \"name\": String(length=100),\n",
    "    #     \"iso2\": CHAR(length=2),\n",
    "    #     \"created_at\": Text\n",
    "    # }\n",
    "    \n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

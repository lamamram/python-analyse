{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calcul multiprocessing\n",
    "\n",
    "#### énoncé\n",
    "1. avaler le fichier villes_france.zip dans pandas\n",
    "2. transformer le zipcode en département\n",
    "3. créer un \"worker\" qui calcule la combinaison de toutes les distances de villes dans un dpt\n",
    "4. multiprocesser les worker dans la pool\n",
    "5. réduire le max total des max locaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from re import sub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from latloncalc.latlon import LatLon, Latitude, Longitude\n",
    "from itertools import combinations\n",
    "from multiprocessing import Pool, cpu_count, current_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "villes_df = pd.read_csv(\n",
    "    \"villes_france.zip\",\n",
    "    encoding=\"utf8\",\n",
    "    # il n'y a pas d'header\n",
    "    header=None,\n",
    "    # donner des nom des colonnes\n",
    "    names=[\"city\", \"zipcode\", \"lon\", \"lat\"]\n",
    ")\n",
    "villes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation du zipcode en dept \n",
    "def get_dept(zc: str):\n",
    "    return \"0\" + zc[0] if len(zc) < 5 else zc[:2]\n",
    "\n",
    "villes_df[\"zipcode\"] = villes_df[\"zipcode\"].apply(get_dept)\n",
    "villes_df.rename(columns={\"zipcode\": \"dept\"}, inplace=True)\n",
    "villes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trouver des doublons de villes + dept\n",
    "villes_df.drop_duplicates(subset=[\"city\", \"dept\"], keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cas de test\n",
    "# creuse_df = villes_df.loc[ villes_df[\"dept\"] == \"23\" ].set_index(\"city\")\n",
    "# calcule des distances des combinaisons à 2 des villes d'un département\n",
    "# en trouvant le max\n",
    "def max_geodesic(df: pd.DataFrame):\n",
    "    max_d, itinerary = 0, \"\"\n",
    "    for v1, v2 in combinations(df.index, r=2):\n",
    "        point1 = LatLon(Latitude(df.loc[v1][\"lat\"]), Longitude(df.loc[v1][\"lon\"]))\n",
    "        point2 = LatLon(Latitude(df.loc[v2][\"lat\"]), Longitude(df.loc[v2][\"lon\"]))\n",
    "        d = point1.distance(point2)\n",
    "        if d > max_d:\n",
    "            max_d = d\n",
    "            itinerary = f\"{v1} <-> {v2}\" \n",
    "    return  itinerary, max_d\n",
    "        \n",
    "# cas d'un département\n",
    "# max_geodesic(creuse_df)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cas unique\n",
    "# point1 = LatLon(Latitude(creuse_df.loc[\"VIERSAT\"][\"lat\"]), Longitude(creuse_df.loc[\"VIERSAT\"][\"lon\"]))\n",
    "# point2 = LatLon(Latitude(creuse_df.loc[\"LUSSAT\"][\"lat\"]), Longitude(creuse_df.loc[\"LUSSAT\"][\"lon\"]))\n",
    "# d = point1.distance(point2)\n",
    "# d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WARNING: pour utiliser des process ou des threading ou des futures ...\n",
    "## on utilise le bloc __name__ == \"__main__\" sinon erreur\n",
    "## IMPOSSIBLE AVEC LE NOTEBOOK JUPYTER ET VSCODE DONC EXPORT EN PYTHON\n",
    "def process():\n",
    "    depts = [\"23\"] #\"13\", \"33\", \"44\", \"15\" \"29\" \"78\", \"81\", \"50\"]\n",
    "    villes_df.set_index(\"city\", inplace=True)\n",
    "    with Pool(cpu_count() - 2) as pool:\n",
    "        ## pool apply => application d'un worker sur un cpu de la pool de manière synchrone\n",
    "        ## pool apply_async =>  //                 //           //       //       asynchronique\n",
    "        # il faut requêter sur le retour de type AsyncResult via o.get()\n",
    "        # pour être sûr il faut attendre le pool.join() qui va bloquer le programme jusqu'à la fin des \n",
    "        # workers\n",
    "        ## pool map => application d'une grappe de worker (même finction) de la manière synchrone\n",
    "        # donne la liste de retour des workers\n",
    "        # WARNING: le worker n'a qu'un seul paramètre\n",
    "        # pour plusieurs paramètres pool.starmap(fn, [(),(),()])\n",
    "        ## pool map_async idem non bloquant => pool.join()\n",
    "        params = [ villes_df.loc[ villes_df[\"dept\"] == dpt ] for dpt in depts ]\n",
    "        results = pool.map(\n",
    "            max_geodesic,\n",
    "            params            \n",
    "        )\n",
    "        print(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
